# JSON-LD Schema Viewer

[English](./README.en.md) | 日本語

WebサイトのJSON-LD構造化データを可視化・検証するツール

本番環境: https://json-ld-view.vercel.app/

## 主な機能

- CORS制限を回避してあらゆるURLにアクセス可能
- localhostのサイトも検証可能
- テーブル形式とJSON形式の切り替え表示
- ワンクリックでJSONをコピー
- 画像URLはサムネイル付きで表示
- AI求人票アドバイザー機能: JobPostingスキーマ検出→採用側/応募者向け分析
- AIブログレビュアー機能: Article/BlogPostingスキーマのSEO・コンテンツ品質分析
- Webアドバイザー（汎用）機能: スキーマ無し/WebPageのみのページ向けSEO/EEAT/アクセシビリティ分析
- コンテンツアップロードレビュアー: ファイル・テキストのAIレビュー、求人×スキルシートマッチング
- スキルシート作成・管理: エンジニア向け職務経歴書の作成・レビュー

## 目次

- [主な機能](#主な機能)
- [使い方（エンドユーザー向け）](#使い方エンドユーザー向け)
  - [JSON-LD抽出と表示](#json-ld抽出と表示)
  - [AI求人票アドバイザー](#ai求人票アドバイザー)
  - [AIブログレビュアー](#aiブログレビュアー)
  - [AIウェブアドバイザー](#aiウェブアドバイザー)
  - [コンテンツアップロードレビュアー](#コンテンツアップロードレビュアー)
  - [スキルシート作成・管理](#スキルシート作成管理)
  - [My API設定（独自APIキー使用）](#my-api設定独自apiキー使用)
- [クイックスタート（開発者向け）](#クイックスタート開発者向け)
- [技術スタック](#技術スタック)
- [API エンドポイント](#api-エンドポイント)
- [セキュリティに関する注意](#セキュリティに関する注意)
- [トラブルシューティング](#トラブルシューティング)

## 使い方（エンドユーザー向け）

### JSON-LD抽出と表示

WebサイトのJSON-LD構造化データを簡単に可視化・検証できます。

#### 基本的な使い方（所要時間: 約1分）

**手順1: サイトにアクセス**

1. ブラウザで https://json-ld-view.vercel.app/ を開く
2. トップページが表示されることを確認

**手順2: URLを入力**

1. 画面上部の「URLを入力してください」というテキストフィールドをクリック
2. 検証したいWebサイトのURLを入力
   - 例: `https://schema.org/`
   - 例: `https://developers.google.com/search/docs/appearance/structured-data`
3. URLは完全な形式で入力（`https://`または`http://`を含む）

**手順3: データを抽出**

1. 「抽出」ボタン（URLフィールドの右側）をクリック
2. 読み込み中のインジケーターが表示されます
3. 数秒後、抽出されたJSON-LDデータが画面に表示されます

**期待される結果**:

- JSON-LDスキーマタイプが表示される（例: Organization, Article, JobPostingなど）
- データがテーブル形式で読みやすく整形される
- 画像URLがある場合、サムネイル画像が表示される

**手順4: 表示形式を切り替え**

1. 画面下部の「テーブル表示」または「JSON表示」ボタンをクリック
   - **テーブル表示**: プロパティと値が表形式で表示（初期状態）
   - **JSON表示**: 生のJSON形式で表示、コード整形済み
2. 表示形式がリアルタイムで切り替わります

**手順5: データをコピー**

1. 「JSONをコピー」ボタンをクリック
2. 「コピーしました」という確認メッセージが表示されます
3. コピーしたデータは、任意のテキストエディタに貼り付け可能

**トラブルシューティング**:

- **「JSON-LDが見つかりませんでした」と表示される**: そのページにJSON-LD構造化データが含まれていません
- **タイムアウトエラー**: 対象サイトのレスポンスが遅い可能性があります。再度試すか、別のURLで試してください
- **CORSエラー**: ブラウザのコンソールにエラーが表示される場合、ページをリロードして再度試してください

#### Basic認証が必要なサイトの場合（所要時間: 約2分）

Basic認証（ユーザー名とパスワードが必要なサイト）でもJSON-LDデータを抽出できます。

**手順1: 認証セクションを開く**

1. URLを入力フィールドに入力
2. URLフィールドの下にある「認証」という折りたたみ可能なセクションをクリック
3. 認証情報入力フォームが展開されます

**手順2: 認証情報を入力**

1. 「ユーザー名」フィールドに認証ユーザー名を入力
2. 「パスワード」フィールドにパスワードを入力
3. パスワードは初期状態で伏せ字（●●●）で表示されます
4. パスワードを確認したい場合は「パスワードを表示」チェックボックスをクリック

**手順3: データを抽出**

1. 「抽出」ボタンをクリック
2. 認証情報が自動的に送信され、サイトにアクセスします
3. 認証が成功すると、JSON-LDデータが表示されます

**期待される結果**:

- 認証が成功し、通常通りJSON-LDデータが表示される
- 認証情報は自動的にローカルストレージに保存される（ドメインごと）
- 次回同じドメインにアクセスする際、認証情報が自動入力される

**手順4: 認証情報の削除（オプション）**

1. 認証セクションを開く
2. 「削除」ボタンをクリック
3. 保存されている認証情報が削除されます
4. 確認メッセージが表示されます

**セキュリティに関する注意**:

- 認証情報はブラウザのローカルストレージにのみ保存されます
- サーバーには送信・保存されません
- パスワードはサーバーログに平文で記録されません

**トラブルシューティング**:

- **「401 Unauthorized」エラー**: ユーザー名またはパスワードが間違っています
- **認証情報が保存されない**: ブラウザのプライベートモードを使用していないか確認してください

#### localhost URLの検証（開発者向け・所要時間: 約3分）

ローカル開発中のサイトもJSON-LD抽出を検証できます。Vercel環境ではlocalhostにアクセスできないため、ローカル環境でツールを起動する必要があります。

**前提条件**:

- Node.js v18以上がインストール済み
- pnpmがインストール済み（`npm install -g pnpm`）
- 検証したいlocalhostサイトが起動中

**手順1: ツールをローカルで起動**

1. ターミナルを開く
2. プロジェクトディレクトリに移動
   ```bash
   cd /path/to/json-scheme-checker
   ```
3. 依存関係をインストール（初回のみ）
   ```bash
   pnpm install
   ```
4. 開発サーバーを起動
   ```bash
   pnpm dev
   ```
5. 「Server is running on http://localhost:3333」というメッセージが表示されることを確認

**手順2: ブラウザでアクセス**

1. ブラウザで `http://localhost:3333` を開く
2. トップページが表示されることを確認

**手順3: localhost URLを入力**

1. URLフィールドに、検証したいlocalhostサイトのURLを入力
   - 例: `http://localhost:8000`
   - 例: `http://localhost:3000/blog/article`
2. 「抽出」ボタンをクリック
3. ツールが自動的にプロキシ経由でlocalhostサイトにアクセスします

**期待される結果**:

- localhostサイトからJSON-LDデータが正常に抽出される
- CORS制限なくアクセスできる

**手順4: LAN内のモバイルデバイスからテスト（オプション）**

1. ターミナルで自分のIPアドレスを確認

   ```bash
   # Mac/Linux
   ifconfig | grep "inet " | grep -v 127.0.0.1

   # Windows
   ipconfig
   ```

2. モバイルデバイスのブラウザで `http://<your-ip>:3333` を開く
   - 例: `http://192.168.1.100:3333`
3. 同じLAN内の別デバイスからでもlocalhostサイトを検証可能

**トラブルシューティング**:

- **ポート3333が使用中**: `lsof -i :3333` でプロセスを確認し、`kill $(lsof -t -i:3333)` で終了
- **localhost接続エラー**: 検証対象のlocalhostサイトが起動しているか確認
- **IPv6エラー**: ツールは自動的に `localhost` を `127.0.0.1` に変換しますが、問題が発生する場合は直接IPアドレスを使用してください

### AI求人票アドバイザー（所要時間: 約3分）

JobPostingスキーマが検出された求人ページを、AIが自動分析してアドバイスを提供します。無料版では50回/24時間まで利用可能です。

**前提条件**:

- JobPostingスキーマを含む求人ページのURL
- 無料版: 24時間以内の使用回数が50回未満
- または独自のOpenAI APIキーを設定済み（無制限）

**手順1: 求人ページのJSON-LDを抽出**

1. 求人ページのURL（例: Indeed、Wantedly、Greenなどの求人詳細ページ）を入力
2. 「抽出」ボタンをクリック
3. JSON-LDデータが表示されることを確認
4. JobPostingスキーマが含まれていることを確認（@type: "JobPosting"）

**期待される結果**:

- 求人情報がテーブル形式で表示される
- 職種、給与、勤務地、雇用形態などのフィールドが表示される
- 「AI求人票アドバイザー」ボタンが自動的に表示される

**手順2: アドバイザーを起動**

1. JSON-LDデータの下に表示される「AI求人票アドバイザー」ボタンをクリック
2. アドバイザーパネルが展開されます
3. 3つの分析視点が表示されます

**手順3: 分析視点を選択**

以下の3つから選択してください:

1. **採用側視点**:
   - 企業の採用担当者向け
   - 求人票の訴求力を向上させる具体的な改善提案
   - 応募者を増やすための戦略
   - 選択するタイミング: 求人票を改善したい場合

2. **応募者視点**:
   - 求職者目線での評価
   - 求人票の魅力度や不足している情報の指摘
   - 応募者が気になるポイントの明確化
   - 選択するタイミング: 応募者がどう感じるか知りたい場合

3. **エージェント視点**:
   - 人材エージェント向け
   - 技術要件の詳細分析
   - 候補者とのマッチング観点
   - 市場価値の評価
   - 選択するタイミング: 技術要件を深掘りしたい場合

**手順4: AI分析の確認**

1. 選択した視点のボタンをクリック
2. 「分析中...」というメッセージが表示されます
3. 数秒後、AIからのアドバイスがリアルタイムでストリーミング表示されます
4. Markdown形式で見出し、リスト、太字などが適用され読みやすく表示されます
5. 分析が完了すると、使用したトークン数とコストが表示されます（My API使用時）

**期待される結果（採用側視点の例）**:

- 求人票の強みと弱みの分析
- 具体的な改善提案（箇条書き）
- 訴求力を高めるキーワードの提案
- 競合との差別化ポイント

**手順5: 結果をエクスポート（オプション）**

分析が完了すると、エクスポートボタンが表示されます:

1. **CSV形式でエクスポート**:
   - 「CSVダウンロード」ボタンをクリック
   - `advisor_result_<timestamp>.csv` がダウンロードされます
   - スプレッドシートで分析結果を管理可能

2. **HTML形式でエクスポート**:
   - 「HTMLダウンロード」ボタンをクリック
   - `advisor_result_<timestamp>.html` がダウンロードされます
   - ブラウザで開いて印刷・共有が可能

**レート制限について**:

- **無料版（サーバーAPIキー使用）**:
  - 50回/24時間まで利用可能
  - 各アドバイザー（JobPosting、Blog、Webアドバイザー）が独立したカウント
  - 残り回数は画面下部に表示されます
  - 制限に達すると「レート制限に達しました」というメッセージが表示されます

- **My API使用時（独自APIキー）**:
  - 無制限に利用可能
  - 使用量とコストをリアルタイムで確認可能
  - OpenAI APIの利用料金が発生します

**トラブルシューティング**:

- **「AI求人票アドバイザー」ボタンが表示されない**: JobPostingスキーマが含まれていません。別の求人ページを試してください
- **「レート制限に達しました」**: 24時間後に再度試すか、独自のAPIキーを設定してください
- **分析が途中で止まる**: ネットワークエラーの可能性があります。再度ボタンをクリックしてください

### AIブログレビュアー

Article/BlogPostingスキーマが検出されたブログ記事を、SEOとコンテンツ品質の観点からAIが分析します。

#### 使い方

1. **ブログ記事のURLを入力**
   - Article/BlogPostingスキーマを含むブログ記事のURLを入力

2. **レビュアーの起動**
   - JSON-LDデータが表示されたら、「AIブログレビュアー」ボタンが表示されます
   - ボタンをクリックしてレビュアーを起動

3. **分析内容**
   - **SEO分析**: タイトル、メタディスクリプション、キーワード最適化
   - **EEAT評価**: 専門性、権威性、信頼性の評価
   - **読者エンゲージメント**: 読みやすさ、構成、引き込み力
   - **コンテンツの質**: 深度、独自性、価値提供

4. **改善提案の確認**
   - 具体的な改善提案がリアルタイムで表示されます
   - 優先度順に対応すべき項目が提示されます

5. **結果のエクスポート**
   - CSV/HTML形式でレビュー結果を保存できます

### AIウェブアドバイザー

スキーマが検出されないページ、またはWebPageスキーマのみのページに対して、包括的なWeb最適化アドバイスを提供します。

#### 使い方

1. **WebページのURLを入力**
   - スキーマなし、またはWebPageのみのページのURLを入力

2. **アドバイザーの起動**
   - 「AIウェブアドバイザー」ボタンをクリック

3. **分析内容**
   - **SEO最適化**: タイトル、メタタグ、見出し構造、構造化データの提案
   - **EEAT評価**: 専門性・権威性・信頼性の観点からの評価
   - **アクセシビリティ**: スクリーンリーダー対応、画像代替テキスト、コントラスト
   - **優先対応事項**: 効果が高い施策を優先度順に提示

4. **ストリーミング表示**
   - リアルタイムでアドバイスが表示されます
   - 分析が進むにつれて、セクションごとに結果が追加されます

### コンテンツアップロードレビュアー

ファイルやテキストをアップロードして、AIによるレビュー・校閲・マッチング分析を行います。

#### 使い方

1. **アップロードボタンをクリック**
   - ヘッダーの「Upload」ボタンをクリック

2. **レビュー種類を選択**
   - **ブログコンテンツレビュー**: 草案記事の分析と改善提案
   - **求人票レビュー**: 求人票の最適化提案
   - **スキルシートレビュー**: スキルシートの分析と改善提案
   - **求人×スキルシートマッチング**: マッチング度評価とギャップ分析
   - **汎用テキストレビュー**: あらゆるテキストの校閲

3. **コンテンツ入力**
   - **テキスト入力**: テキストエリアに直接貼り付け
   - **ファイルアップロード**: ドラッグ&ドロップまたはファイル選択
   - 対応形式: PDF, CSV, Excel, Markdown, JSON, TXT

4. **レビュー開始**
   - 「レビュー開始」ボタンをクリック

5. **結果確認**
   - **Diff形式**: 左側に元の内容、右側に校閲済みの内容を表示
   - 変更箇所が色分けされて表示されます

6. **エクスポート**
   - **コピー**: 校閲済みテキストをクリップボードにコピー
   - **ダウンロード**: Markdown形式でファイル保存

#### 求人×スキルシートマッチングの使い方

1. **レビュー種類で「求人×スキルシートマッチング」を選択**

2. **求人票を入力**
   - URLを入力、またはテキストで求人票を貼り付け

3. **スキルシートをアップロード**
   - テキスト入力またはファイル（PDF、Markdown等）をアップロード

4. **マッチング分析を確認**
   - **マッチング度スコア**: 0-100点で評価
   - **ギャップ分析**: 不足しているスキルや経験
   - **キャリアアップ提案**: 成長のための具体的なアドバイス

### スキルシート作成・管理

エンジニア向けのスキルシート（職務経歴書）を作成・管理できます。

#### 使い方

1. **My Skill Sheetボタンをクリック**
   - ヘッダーの「My Skill Sheet」ボタンをクリック

2. **タブを切り替えて入力**
   - **基本情報**: 氏名、生年月日、居住地、連絡先
   - **プロフェッショナル**: 職種、経験年数、希望条件、英語力
   - **学歴**: 学歴情報の入力
   - **職務経歴**: 複数の職務経験を登録（会社名、期間、職種、業務内容）
   - **プロジェクト実績**: プロジェクトごとの詳細（役割、使用技術、成果）
   - **スキル**: 言語、フレームワーク、データベース、インフラ、ツール別にスキルを入力
   - **資格**: 取得資格・認定の登録
   - **リンク**: GitHub、Qiita、ポートフォリオ、LinkedIn、ブログのURL
   - **プロフィール**: サマリー、人物像、強み、キャリア目標

3. **自動保存**
   - 入力内容は自動的にブラウザのローカルストレージに保存されます
   - 複数バージョンの履歴管理が可能

4. **エクスポート**
   - **Markdown形式**: 読みやすいMarkdown形式で保存
   - **JSON形式**: データとして保存・バックアップ
   - **テキスト形式**: プレーンテキストで保存

5. **AIレビュー**
   - 「レビューする」ボタンでContent Upload Reviewerに送信
   - AIによる改善提案を取得

6. **求人マッチング**
   - レビュー画面で「求人×スキルシートマッチング」を選択
   - 求人票URLまたはテキストを入力してマッチング分析

### My API設定（独自APIキー使用）

独自のOpenAI APIキーを設定することで、レート制限なしで全機能を利用できます。

#### 設定方法

1. **My APIボタンをクリック**
   - ヘッダーの「My API」ボタンをクリック

2. **APIキーを入力**
   - OpenAI APIキー（`sk-...`形式）を入力
   - APIキーはブラウザのローカルストレージにのみ保存され、サーバーには送信されません

3. **モデルを選択**
   - **無料版（サーバーAPIキー使用時）**:
     - gpt-5-nano（既定）: 超低レイテンシ、最もコスト効率が高い
     - gpt-4.1-nano: レガシーnano系、互換性重視
   - **My API使用時（独自APIキー）**:
     - gpt-5, gpt-5-mini
     - gpt-4.1, gpt-4.1-mini
     - gpt-4o, gpt-4o-mini
     - gpt-3.5-turbo
     - o3, o3-mini

4. **保存**
   - 「保存」ボタンをクリックして設定を保存

5. **使用量の確認**
   - 各AI分析実行後に、使用したトークン数とコストが表示されます

#### My API使用のメリット

- **レート制限なし**: 無制限にAI分析を実行可能
- **高性能モデル**: gpt-5、gpt-4.1などの高性能モデルが使用可能
- **コスト管理**: 使用量とコストをリアルタイムで確認
- **プライバシー**: データがサーバーに保存されません

## クイックスタート（開発者向け）

### デスクトップアプリとして起動（推奨）

```bash
# 依存関係インストール
pnpm install

# Electronアプリを起動
pnpm electron:dev
```

Mac/Windowsのネイティブアプリとして起動します。詳細は[ELECTRON.md](./ELECTRON.md)を参照してください。

### ローカル開発（Webアプリ）

```bash
# 依存関係インストール
pnpm install

# 開発サーバー起動（自動再起動）
pnpm dev

# ブラウザで開く
# http://localhost:3333
```

### 環境変数設定（AI機能を使用する場合）

```bash
cp .env.example .env
# .envを編集してOpenAI APIキーを設定
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-5-nano
```

### Vercelへのデプロイ

```bash
vercel --prod
```

Vercelダッシュボードで環境変数を設定してください。

### AI自動修正システム（GitHub Actions）

PRの作成・更新時に自動的に問題を検出し、修正します。

#### 主な機能

- ESLint、フォーマット、CSS、テストの自動チェック
- 簡単な問題は自動修正
- 複雑な問題はClaude AIが分析して修正提案
- PRに詳細なレポートを自動投稿

#### セットアップ

詳細な手順は以下のドキュメントを参照：

```bash
# メインのセットアップガイド
cat GITHUB_UI_SETUP_GUIDE.md

# または、ドキュメント一覧を確認
cat SETUP_INDEX.md
```

必要な設定（5-10分）:

1. Claude APIキーの取得と登録
2. GitHub Actionsの権限設定

動作テスト:

```bash
./test-ai-autofix.sh
```

詳細: [AI自動修正システムのドキュメント](./SETUP_INDEX.md)

## 技術スタック

- **バックエンド**: Node.js + Express + Axios
- **フロントエンド**: Vanilla JavaScript + CSS3 + HTML5
- **デスクトップアプリ**: Electron（Mac/Windows対応）
- **AI機能**: OpenAI GPT-5 nano

## プロジェクト構成

```text
├── server.js                    # Express プロキシサーバー
├── electron/                    # Electronデスクトップアプリ
│   ├── main.js                  # メインプロセス
│   └── preload.js               # プリロードスクリプト
├── public/
│   ├── index.html               # Webアプリケーション
│   ├── web-advisor-demo.html    # Webアドバイザーデモ
│   ├── styles.css               # スタイルシート
│   ├── app.js                   # メインロジック
│   └── modules/                 # 機能モジュール
├── api/
│   ├── proxy.js                 # Vercel サーバーレス関数（プロキシ）
│   ├── advisor.js               # JobPosting AI分析エンドポイント
│   └── web-advisor.js           # Webアドバイザー（汎用）エンドポイント
├── vercel.json                  # Vercel設定
├── ELECTRON.md                  # デスクトップアプリドキュメント
└── .env.example                 # 環境変数テンプレート
```

## API エンドポイント

### GET /proxy

指定URLのHTMLを取得

```bash
curl "http://localhost:3333/proxy?url=https://example.com"
```

### POST /extract-jsonld

URLからJSON-LDを直接抽出

```bash
curl -X POST http://localhost:3333/extract-jsonld \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

### POST /api/advisor

JobPosting分析（ストリーミング）

```bash
curl -X POST http://localhost:3333/api/advisor \
  -H "Content-Type: application/json" \
  -d '{"jobPosting": {...}, "mode": "employer"}'
```

### GET /api/web-advisor

Webアドバイザー（汎用）- スキーマ無し/WebPageのみのページ向けAI分析（SSE）

```bash
# 基本的な使用
curl -N "http://localhost:3333/api/web-advisor?url=https://example.com"

# 独自のAPIキーを使用（レート制限スキップ）
curl -N "http://localhost:3333/api/web-advisor?url=https://example.com&userApiKey=sk-..."
```

**レスポンス形式**: Server-Sent Events (SSE)

**SSEイベントタイプ**:

- `init`: 初期化（分析開始）
- `progress`: 進捗状況（stage: fetching/parsing/analyzing）
- `meta`: 抽出されたメタ情報（title, description, OG, Twitter, headings, body）
- `token`: ストリーミングされるMarkdownトークン
- `done`: 完了
- `error`: エラー

**分析内容**:

- SEO（タイトル、メタディスクリプション、見出し構造、構造化データ）
- EEAT（専門性、権威性、信頼性）
- アクセシビリティ（見出し構造、画像alt、コントラスト）
- 優先対応事項
- 総括

### GET /health

ヘルスチェック

```bash
curl http://localhost:3333/health
```

## Webアドバイザー（汎用）

スキーマが検出されないページ、またはWebPageスキーマのみのページに対して、AI駆動の包括的なアドバイスを提供します。

### 主な機能

- **SEO最適化提案**: タイトル、メタディスクリプション、見出し構造、構造化データの改善案
- **EEAT分析**: 専門性・権威性・信頼性の観点から評価とアドバイス
- **アクセシビリティ評価**: スクリーンリーダー対応、コントラスト、代替テキストの提案
- **優先対応事項**: 効果が高い施策を優先度順に提示
- **ストリーミング表示**: リアルタイムでアドバイスを表示

### 使い方

#### 1. デモページで試す

```bash
# サーバー起動
npm run dev

# ブラウザで開く
open http://localhost:3333/web-advisor-demo.html
```

デモページの機能：

- URL入力フィールド
- OpenAI APIキー入力（オプション）
- リアルタイムストリーミング表示
- コピー/保存/再実行機能

#### 2. プログラムから利用

```javascript
// EventSourceを使用したSSE接続
const url = encodeURIComponent('https://example.com');
const eventSource = new EventSource(`/api/web-advisor?url=${url}`);

eventSource.addEventListener('message', event => {
  const data = JSON.parse(event.data);

  switch (data.type) {
    case 'init':
      console.log('開始:', data.message);
      break;
    case 'progress':
      console.log('進捗:', data.stage, data.message);
      break;
    case 'meta':
      console.log('メタ情報:', data.data);
      break;
    case 'token':
      // Markdownトークンを画面に追加
      appendContent(data.content);
      break;
    case 'done':
      console.log('完了');
      eventSource.close();
      break;
    case 'error':
      console.error('エラー:', data.message);
      eventSource.close();
      break;
  }
});
```

#### 3. OpenAI APIキーを使用

環境変数で設定（サーバー側）:

```bash
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-5-nano
```

またはクエリパラメータで指定（ユーザー側）:

```bash
curl -N "http://localhost:3333/api/web-advisor?url=https://example.com&userApiKey=sk-..."
```

**注意**: APIキーが設定されていない場合は、テンプレートベースのアドバイスが提供されます。

### タイムアウト設定

- **接続タイムアウト**: 15秒
- **HTML取得タイムアウト**: 25秒
- **AI分析タイムアウト**: 120秒
- **Keepalive**: 15秒ごと

## セキュリティに関する注意

### レート制限

レート制限はブラウザ側（localStorage）で管理されます。各アドバイザーが独立した制限を持つため、複数人が同じ IP からアクセスしても、各ブラウザで 50 回ずつ使用できます。

#### 無料版（MyAPI なし）

各アドバイザーが独立して 50回/24時間の制限を持ちます：

| アドバイザー     | localStorage キー            | 制限        |
| ---------------- | ---------------------------- | ----------- |
| JobPosting       | `jsonld_advisor_usage`       | 50回/24時間 |
| ブログレビュアー | `jsonld_blog_reviewer_usage` | 50回/24時間 |
| Webアドバイザー  | `jsonld_web_advisor_usage`   | 50回/24時間 |

各アドバイザーは**ブラウザごとに独立したカウント**です。複数のアドバイザーを使用する場合、各々が 50 回まで使用できます。

**複数人が同一 IP からアクセスする場合**:

企業オフィスなど複数人が同じ Wifi を使用しても、各従業員のブラウザが独立した localStorage を持つため、誰もが 50 回ずつ AI 分析を利用できます。

#### 開発者モード（MyAPI 使用時）

独自の OpenAI APIキー（`userApiKey` / `jsonld_user_openai_key`）を設定した場合：

- レート制限：**無制限**（制限なし）
- 好きなだけ AI 分析を利用可能

### モデル利用制限

#### 公開無料版で利用可能なモデル

サーバー既定のAPIキーを使用する場合、現在選択可能なモデルは次のとおりです：

- **gpt-5-nano**（既定）: 超低レイテンシかつ最新料金で最もコスト効率が高い
- **gpt-4.1-nano**: 既存ワークロードとの互換性を重視したレガシーnano系

どちらのモデルも無料枠内で利用でき、切り替え設定は「My API」モーダルの無料版セレクトから行えます。

#### gpt-5-nano と gpt-4.1-nano の比較（本プロダクト観点）

- **速度/レイテンシ**
  - gpt-5-nano: 初回トークンまでが短く、SSEの体感が最もスムーズ
  - gpt-4.1-nano: 5-nano比でやや遅い
- **コスト（MyAPI利用時の目安）**
  - gpt-5-nano: 低コスト
  - gpt-4.1-nano: 5-nanoより高コスト
- **パラメータ制御**
  - gpt-5-nano: temperature / top_p 等は非対応（本プロダクトでも送信しない）
  - gpt-4.1-nano: MyAPI時に temperature などの調整が可能
- **出力傾向**
  - gpt-5-nano: 簡潔・要点重視で高速
  - gpt-4.1-nano: 旧4.1系プロンプトとの互換が高く、口調調整が効きやすい
- **無料枠カウント**
  - JobPosting: 50回/24h（`jsonld_advisor_usage`）
  - ブログレビュアー: 50回/24h（`jsonld_blog_reviewer_usage`）
  - Webアドバイザー: 50回/24h（`jsonld_web_advisor_usage`）
  - 各アドバイザーは独立したカウント（合算ではない）

##### 推奨の使い分け

- まずは既定の **gpt-5-nano**（高速・安価・安定）
- 次の場合は **gpt-4.1-nano**
  - 旧4.1系前提のプロンプトや互換要件がある
  - MyAPIで温度や創作度合いを細かくコントロールしたい
  - 既存ドキュメント/テンプレに対して4.1系の出力が適合しやすい

#### MyAPI必須のモデル

以下のモデルを使用するには、**MyAPIモード（独自のOpenAI APIキー）が必須**です：

- gpt-5, gpt-5-mini
- gpt-4.1, gpt-4.1-mini
- gpt-4o, gpt-4o-mini
- gpt-3.5-turbo
- o3, o3-mini

MyAPIモードの設定方法：

1. ヘッダーの「My API」ボタンをクリック
2. 独自のOpenAI APIキーを入力
3. 使用したいモデルを選択
4. 保存

詳細は[MODEL_PRICING.md](./docs/MODEL_PRICING.md)を参照してください。

### APIキー管理

- サーバーAPIキーは環境変数で保護
- ユーザーが自分のAPIキーを使用することも可能
- `.env`ファイルは`.gitignore`に含まれています

## 制限事項

### Vercel環境

- タイムアウト: 無料プラン10秒、Proプラン60秒
- localhost URLアクセスにはCORS設定が必要
- 同時接続数に制限あり

### 推奨

localhost URLをテストする場合はローカル環境で起動してください。

## トラブルシューティング

| 問題                  | 解決方法                                              |
| --------------------- | ----------------------------------------------------- |
| CORSエラー            | サーバーが起動していることを確認、`/health`でチェック |
| localhostアクセス不可 | Vercelではなくローカル環境を使用、ポート番号を確認    |
| タイムアウト          | 対象サイトのレスポンスが遅い、ネットワークを確認      |
| AI機能が動作しない    | OpenAI APIキーを設定、環境変数を確認                  |

## AIアシスタント (Claude Code) の活用

このプロジェクトでは、開発効率を最大化するためにAIアシスタント(Claude Code)を積極的に活用しています。AIは、MCP(Model Context Protocol)という仕組みを通じて、ドキュメント検索やコードレビューといった様々なタスクを自動化します。

初めての方は、まず以下のガイドで全体像を把握することをお勧めします。

- **[AIアシスタント活用ガイド](./.ai-docs/AI_ASSISTANT_GUIDE.md)** - **（まずここから）** MCP、Skills、SubAgentなど、AI関連機能の全体像を解説しています。

### クイックリファレンス: 主なスキル

- `code-review`: コードレビューを実行
- `api-check`: API仕様の品質をチェック
- `deploy-check`: デプロイ前のチェックリストを実行

詳細は各ガイドを参照してください。

### GitHub Actions自動レビュー

このプロジェクトではGitHub Actionsを使用した**オプショナルな自動コードレビュー**を実装しています。

#### 実行方法

#### 方法1: 手動トリガー

GitHub UIから手動でレビューを実行します：

```bash
# GitHub リポジトリ → Actions → Claude Code Review → Run workflow
```

#### 方法2: PR説明に [review] キーワードを含める

PR説明文に `[review]` を含めることで、自動的にレビューが実行されます：

```markdown
## PR説明

バグ修正: ユーザー認証の問題を修正

[review]
```

#### 方法3: GitHub コメントで /code-review または @claude を記述

PR やイシューのコメントで以下のいずれかを記述するとレビューが実行されます：

```markdown
/code-review
```

または

```markdown
@claude このコードをレビューしてください
```

#### レビュー内容

自動レビューでは以下の観点から分析します：

- コード品質とベストプラクティス
- 潜在的なバグや問題
- パフォーマンスの考慮
- セキュリティの懸念
- テストカバレッジ

レビュー結果はPRコメントとして自動投稿されます。

## ドキュメント

- [Claude Code開発ガイド](./CLAUDE.md) - 開発環境の設定と使用方法
- [Claude Code Skills ガイド](./.ai-docs/shared/09_CLAUDE_CODE_SKILLS.md) - カスタムスキルの詳細

## 参考リンク

- [Schema.org](https://schema.org/)
- [JSON-LD仕様](https://json-ld.org/)
- [OpenAI API](https://platform.openai.com/)

## ライセンス

MIT

## 貢献

プルリクエストを歓迎します。大きな変更の場合はissueで事前に相談してください。
